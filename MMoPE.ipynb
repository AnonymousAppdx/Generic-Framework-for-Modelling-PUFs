{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: 265.58 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pypuf.simulation import *\n",
    "import pypuf.metrics as pm\n",
    "from pypuf.io import random_inputs\n",
    "import pypuf.io, pypuf.simulation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import metrics, activations\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from mmoe import MMoE\n",
    "import datetime\n",
    "import psutil\n",
    "from tensorflow.python.profiler import profiler_client\n",
    "from preprocessing import *\n",
    "\n",
    "process = psutil.Process()\n",
    "memory_info_start = process.memory_info()\n",
    "\n",
    "# Memory cost\n",
    "print(f\"Memory: {memory_info_start.rss / (1024 ** 2):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     \n",
    "def Model_Multiple_PUFs(units_mmoe,gate_activation,N_train,train_c,test_c,train_r_groups,test_r_groups,PUF_list,num_expert=7):    \n",
    "    num_features = 64\n",
    "    input_layer = Input(shape=(num_features,))\n",
    "    experts_list = []\n",
    "    activation = 'relu'\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    drop_out_rate = 0.2\n",
    "    num_neu = 2**5\n",
    "\n",
    "    # Build the PUF experts\n",
    "    experts_list = [Expert_customize([num_neu,num_neu],activation=activation,kernel_init=kernel_init,drop_out_rate=drop_out_rate)\n",
    "                    for _ in range(num_expert)]\n",
    "    tower_units = [num_neu for _ in range(PUF_list.n_pufs)]\n",
    "\n",
    "\n",
    "    # Set up MMoPE layer\n",
    "    mmoe_layers = MMoE(\n",
    "        units=units_mmoe,\n",
    "        # num_experts=num_experts,\n",
    "        use_gate_bias=True,\n",
    "        experts=experts_list,\n",
    "        num_tasks=PUF_list.n_pufs,\n",
    "        expert_activation=activation,\n",
    "        gate_activation=gate_activation,\n",
    "        dropout_rate=0.1,\n",
    "    )(input_layer)\n",
    "\n",
    "\n",
    "    output_layers = []\n",
    "    def lr_schedule(epoch, lr):\n",
    "        if epoch < 30:\n",
    "            return 0.01\n",
    "        elif epoch < 60:\n",
    "            return 0.005\n",
    "        elif epoch < 300:\n",
    "            return 0.001\n",
    "        else:\n",
    "            return 0.001\n",
    "    # output_info = ['r1', 'r2', 'r3','r4','r5']\n",
    "    output_info = ['r'+str(i) for i in range(1,PUF_list.n_pufs+1)]\n",
    "    loss_dict = {'r'+str(i): 'binary_crossentropy' for i in range(1,PUF_list.n_pufs+1)}\n",
    "    # output_info = ['r1', 'r2']\n",
    "    train_losses = {output: [] for output in output_info}\n",
    "    train_accuracies = {output: [] for output in output_info}\n",
    "    val_losses = {output: [] for output in output_info}\n",
    "    val_accuracies = {output: [] for output in output_info}\n",
    "\n",
    "    # Custom callback to collect training history\n",
    "    class HistoryCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            for output in output_info:\n",
    "                train_losses[output].append(logs.get(f'{output}_binary_loss'))\n",
    "                train_accuracies[output].append(logs.get(f'{output}_binary_accuracy'))\n",
    "                val_losses[output].append(logs.get(f'val_{output}_binary_loss'))\n",
    "                val_accuracies[output].append(logs.get(f'val_{output}_binary_accuracy'))\n",
    "\n",
    "    # Build tower layer from MMoE layer\n",
    "    for index, task_layer in enumerate(mmoe_layers):\n",
    "        tower_layer = Dense(\n",
    "            units=tower_units[index],\n",
    "            activation=activation)(task_layer)\n",
    "        output_layer = Dense(\n",
    "            units=1,\n",
    "            name=output_info[index],\n",
    "            activation='sigmoid',\n",
    "            kernel_initializer=kernel_init)(tower_layer)\n",
    "        output_layers.append(output_layer)\n",
    "\n",
    "    \n",
    "    \n",
    "    class LossWeightCallback(tf.keras.callbacks.Callback):\n",
    "        def __init__(self, output_info,custom_layer, **kwargs):\n",
    "            super(LossWeightCallback, self).__init__(**kwargs)\n",
    "            self.output_info = output_info\n",
    "            self.num_task = len(self.output_info)\n",
    "            self.custom_layer = custom_layer\n",
    "            self.dynamic_loss_weights = [K.variable(1.0) for _ in range(PUF_list.n_pufs)]\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            logs = logs or {}\n",
    "            Done = 0\n",
    "            for i in range(self.num_task):\n",
    "                current_accuracy = logs.get(self.output_info[i]+'_accuracy')\n",
    "                # weight = 2 - 2*current_accuracy\n",
    "                if current_accuracy>0.90:\n",
    "                    K.set_value(self.custom_layer[i].threshold,0.01)\n",
    "                    Done += 1\n",
    "                    # weight=0.0\n",
    "                # else:\n",
    "                    weight = 2 - 2*current_accuracy\n",
    "                    K.set_value(self.dynamic_loss_weights[i],weight)\n",
    "                elif current_accuracy>0.8:\n",
    "                    K.set_value(self.custom_layer[i].threshold,0.005)\n",
    "                elif current_accuracy>0.7:\n",
    "                    K.set_value(self.custom_layer[i].threshold,0.001)\n",
    "                elif current_accuracy>0.6:\n",
    "                    K.set_value(self.custom_layer[i].threshold,0.00001)\n",
    "            if Done==self.num_task:\n",
    "                self.model.stop_training = True\n",
    "                print(\"Early Stop!\")\n",
    "                    # self.custom_layer[i].experts_needed = 7\n",
    "    LossWeightUpdate = LossWeightCallback(output_info=output_info,custom_layer=gate_activation)\n",
    "           \n",
    "    # Compile model\n",
    "    model = Model(inputs=[input_layer], outputs=output_layers)\n",
    "    optimizer = 'adam'\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        loss_weights=LossWeightUpdate.dynamic_loss_weights,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    batch_size = min(N_train//40,20000)\n",
    "\n",
    "    history = model.fit(\n",
    "        x=train_c,\n",
    "        y=train_r_groups,\n",
    "        validation_data=(test_c, test_r_groups),\n",
    "        batch_size=batch_size,\n",
    "        epochs=1000\n",
    "        ,callbacks = [LossWeightUpdate]\n",
    "    )\n",
    "    return model, history,output_info,train_losses,train_accuracies,val_losses,val_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRP seed= 34\n",
      "seed= 219\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "PUF_list = PUFs(stages=64, similarity=2)\n",
    "PUF_list.seed = random.randint(1,1000)\n",
    "CRP_seed = random.randint(1,100)\n",
    "print(\"CRP seed=\",CRP_seed)\n",
    "print(\"seed=\",PUF_list.seed)\n",
    "N_train = 300000\n",
    "# PUF_list.add_XOR_PUF(k=2,num=1)\n",
    "PUF_list.add_XOR_PUF(k=4,num=1)\n",
    "PUF_list.add_XOR_PUF(k=3,num=1)\n",
    "# PUF_list.add_XOR_PUF(k=2,num=1)\n",
    "PUF_list.add_XOR_PUF(k=5,num=1)\n",
    "# PUF_list.add_FF_PUF([(32,50)],1)\n",
    "# PUF_list.add_herero_XORFF_PUFs(k=2,ff=[[(20,50),(19,52)],[(21,54),(22,55)],[(30,60),(31,62)]],num=1)\n",
    "# PUF_list.add_herero_XORFF_PUFs(k=3,ff=[[(20,50)],[(21,54)],[(30,60)]],num=1)\n",
    "# PUF_list.add_interpose_PUFs(1,5,1)\n",
    "# PUF_list.add_interpose_PUFs(2,2,1)\n",
    "# PUF_list.add_interpose_PUFs(3,3,1)\n",
    "# PUF_list.add_XORFF_PUF(2,[(20,50)],1)\n",
    "# PUF_list.add_XORFF_PUF(4,[(20,50),(21,54)],1)\n",
    "# PUF_list.add_XORFF_PUF(3,[(20,50),(21,54)],1)\n",
    "# PUF_list.add_XORFF_PUF(2,[(21,54)],1)\n",
    "# PUF_list.add_XORFF_PUF(2,[(21,54),(10,40)],1)\n",
    "# PUF_list.add_XORFF_PUF(1,[(20,50),(10,40),(30,60)],1)\n",
    "# PUF_list.add_XOR_PUF(1,num=1)\n",
    "\n",
    "[c, responses] = PUF_list.generate_crps(CRP_seed,N_train)\n",
    "c = get_parity_vectors2(c)\n",
    "responses = np.array(responses)\n",
    "train_c,test_c,train_r,test_r = train_test_split(c,responses.T,test_size=0.2, random_state=42)\n",
    "train_r_groups = [train_r[:,i].reshape(-1,1) for i in range(PUF_list.n_pufs)]\n",
    "test_r_groups = [test_r[:,i].reshape(-1,1) for i in range(PUF_list.n_pufs)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling three PUFs:\n",
    "- 3-XOR APUF\n",
    "- 4-XOR APUF\n",
    "- 5-XOR APUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "m_mo_e_1 (MMoE)                 [(None, 32), (None,  66626       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 32)           1056        m_mo_e_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 32)           1056        m_mo_e_1[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 32)           1056        m_mo_e_1[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "r1 (Dense)                      (None, 1)            33          dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "r2 (Dense)                      (None, 1)            33          dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "r3 (Dense)                      (None, 1)            33          dense_85[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 69,893\n",
      "Trainable params: 69,890\n",
      "Non-trainable params: 3\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss.\n",
      " 5/32 [===>..........................] - ETA: 1s - loss: 2.1047 - r1_loss: 0.7037 - r2_loss: 0.7045 - r3_loss: 0.6966 - r1_accuracy: 0.4950 - r2_accuracy: 0.4987 - r3_accuracy: 0.5028WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0330s). Check your callbacks.\n",
      "32/32 [==============================] - 4s 64ms/step - loss: 2.0926 - r1_loss: 0.6980 - r2_loss: 0.6988 - r3_loss: 0.6959 - r1_accuracy: 0.4997 - r2_accuracy: 0.5004 - r3_accuracy: 0.5005 - val_loss: 2.0801 - val_r1_loss: 0.6937 - val_r2_loss: 0.6926 - val_r3_loss: 0.6938 - val_r1_accuracy: 0.5070 - val_r2_accuracy: 0.5163 - val_r3_accuracy: 0.5002\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 2.0783 - r1_loss: 0.6933 - r2_loss: 0.6915 - r3_loss: 0.6935 - r1_accuracy: 0.5071 - r2_accuracy: 0.5236 - r3_accuracy: 0.5027 - val_loss: 2.0766 - val_r1_loss: 0.6931 - val_r2_loss: 0.6899 - val_r3_loss: 0.6935 - val_r1_accuracy: 0.5077 - val_r2_accuracy: 0.5336 - val_r3_accuracy: 0.5001\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 2.0742 - r1_loss: 0.6931 - r2_loss: 0.6880 - r3_loss: 0.6931 - r1_accuracy: 0.5078 - r2_accuracy: 0.5470 - r3_accuracy: 0.5073 - val_loss: 2.0741 - val_r1_loss: 0.6930 - val_r2_loss: 0.6876 - val_r3_loss: 0.6934 - val_r1_accuracy: 0.5105 - val_r2_accuracy: 0.5529 - val_r3_accuracy: 0.5047\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 2s 63ms/step - loss: 2.0695 - r1_loss: 0.6927 - r2_loss: 0.6838 - r3_loss: 0.6931 - r1_accuracy: 0.5133 - r2_accuracy: 0.5645 - r3_accuracy: 0.5074 - val_loss: 2.0698 - val_r1_loss: 0.6929 - val_r2_loss: 0.6833 - val_r3_loss: 0.6936 - val_r1_accuracy: 0.5087 - val_r2_accuracy: 0.5681 - val_r3_accuracy: 0.5000\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 2s 64ms/step - loss: 2.0634 - r1_loss: 0.6923 - r2_loss: 0.6782 - r3_loss: 0.6929 - r1_accuracy: 0.5162 - r2_accuracy: 0.5787 - r3_accuracy: 0.5095 - val_loss: 2.0595 - val_r1_loss: 0.6927 - val_r2_loss: 0.6731 - val_r3_loss: 0.6936 - val_r1_accuracy: 0.5120 - val_r2_accuracy: 0.5813 - val_r3_accuracy: 0.4995\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 2s 66ms/step - loss: 2.0493 - r1_loss: 0.6919 - r2_loss: 0.6646 - r3_loss: 0.6928 - r1_accuracy: 0.5187 - r2_accuracy: 0.5943 - r3_accuracy: 0.5112 - val_loss: 2.0337 - val_r1_loss: 0.6925 - val_r2_loss: 0.6476 - val_r3_loss: 0.6937 - val_r1_accuracy: 0.5136 - val_r2_accuracy: 0.6080 - val_r3_accuracy: 0.4996\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 2s 68ms/step - loss: 2.0122 - r1_loss: 0.6917 - r2_loss: 0.6278 - r3_loss: 0.6927 - r1_accuracy: 0.5192 - r2_accuracy: 0.6301 - r3_accuracy: 0.5138 - val_loss: 1.9581 - val_r1_loss: 0.6927 - val_r2_loss: 0.5714 - val_r3_loss: 0.6940 - val_r1_accuracy: 0.5129 - val_r2_accuracy: 0.6773 - val_r3_accuracy: 0.4992\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 1.9134 - r1_loss: 0.6915 - r2_loss: 0.5293 - r3_loss: 0.6926 - r1_accuracy: 0.5199 - r2_accuracy: 0.7135 - r3_accuracy: 0.5125 - val_loss: 1.8288 - val_r1_loss: 0.6927 - val_r2_loss: 0.4423 - val_r3_loss: 0.6939 - val_r1_accuracy: 0.5105 - val_r2_accuracy: 0.7739 - val_r3_accuracy: 0.5022\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 1.7965 - r1_loss: 0.6914 - r2_loss: 0.4124 - r3_loss: 0.6927 - r1_accuracy: 0.5187 - r2_accuracy: 0.7978 - r3_accuracy: 0.5106 - val_loss: 1.7518 - val_r1_loss: 0.6922 - val_r2_loss: 0.3658 - val_r3_loss: 0.6938 - val_r1_accuracy: 0.5125 - val_r2_accuracy: 0.8261 - val_r3_accuracy: 0.4992\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.7309 - r1_loss: 0.6906 - r2_loss: 0.3477 - r3_loss: 0.6926 - r1_accuracy: 0.5217 - r2_accuracy: 0.8371 - r3_accuracy: 0.5146 - val_loss: 1.7092 - val_r1_loss: 0.6914 - val_r2_loss: 0.3238 - val_r3_loss: 0.6940 - val_r1_accuracy: 0.5127 - val_r2_accuracy: 0.8508 - val_r3_accuracy: 0.4999\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.6876 - r1_loss: 0.6891 - r2_loss: 0.3063 - r3_loss: 0.6922 - r1_accuracy: 0.5252 - r2_accuracy: 0.8594 - r3_accuracy: 0.5181 - val_loss: 1.6791 - val_r1_loss: 0.6898 - val_r2_loss: 0.2955 - val_r3_loss: 0.6938 - val_r1_accuracy: 0.5140 - val_r2_accuracy: 0.8644 - val_r3_accuracy: 0.5039\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.6577 - r1_loss: 0.6873 - r2_loss: 0.2779 - r3_loss: 0.6925 - r1_accuracy: 0.5270 - r2_accuracy: 0.8747 - r3_accuracy: 0.5136 - val_loss: 1.6488 - val_r1_loss: 0.6876 - val_r2_loss: 0.2674 - val_r3_loss: 0.6939 - val_r1_accuracy: 0.5198 - val_r2_accuracy: 0.8793 - val_r3_accuracy: 0.5016\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 1.6301 - r1_loss: 0.6848 - r2_loss: 0.2530 - r3_loss: 0.6923 - r1_accuracy: 0.5326 - r2_accuracy: 0.8884 - r3_accuracy: 0.5164 - val_loss: 1.6324 - val_r1_loss: 0.6851 - val_r2_loss: 0.2534 - val_r3_loss: 0.6939 - val_r1_accuracy: 0.5290 - val_r2_accuracy: 0.8863 - val_r3_accuracy: 0.5033\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.6087 - r1_loss: 0.6820 - r2_loss: 0.2345 - r3_loss: 0.6922 - r1_accuracy: 0.5412 - r2_accuracy: 0.8973 - r3_accuracy: 0.5178 - val_loss: 1.6100 - val_r1_loss: 0.6819 - val_r2_loss: 0.2340 - val_r3_loss: 0.6941 - val_r1_accuracy: 0.5368 - val_r2_accuracy: 0.8943 - val_r3_accuracy: 0.5018\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 1.5899 - r1_loss: 0.6777 - r2_loss: 0.2200 - r3_loss: 0.6922 - r1_accuracy: 0.5528 - r2_accuracy: 0.9047 - r3_accuracy: 0.5165 - val_loss: 1.5940 - val_r1_loss: 0.6766 - val_r2_loss: 0.2234 - val_r3_loss: 0.6940 - val_r1_accuracy: 0.5496 - val_r2_accuracy: 0.9020 - val_r3_accuracy: 0.5026\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 1.4032 - r1_loss: 0.6717 - r2_loss: 0.2084 - r3_loss: 0.6920 - r1_accuracy: 0.5642 - r2_accuracy: 0.9097 - r3_accuracy: 0.5182 - val_loss: 1.4034 - val_r1_loss: 0.6683 - val_r2_loss: 0.2168 - val_r3_loss: 0.6941 - val_r1_accuracy: 0.5706 - val_r2_accuracy: 0.9026 - val_r3_accuracy: 0.5030\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 1.3873 - r1_loss: 0.6587 - r2_loss: 0.2042 - r3_loss: 0.6919 - r1_accuracy: 0.5898 - r2_accuracy: 0.9115 - r3_accuracy: 0.5171 - val_loss: 1.3783 - val_r1_loss: 0.6454 - val_r2_loss: 0.2158 - val_r3_loss: 0.6941 - val_r1_accuracy: 0.6082 - val_r2_accuracy: 0.9044 - val_r3_accuracy: 0.5013\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 1.3608 - r1_loss: 0.6331 - r2_loss: 0.2027 - r3_loss: 0.6918 - r1_accuracy: 0.6257 - r2_accuracy: 0.9132 - r3_accuracy: 0.5196 - val_loss: 1.3474 - val_r1_loss: 0.6155 - val_r2_loss: 0.2129 - val_r3_loss: 0.6943 - val_r1_accuracy: 0.6476 - val_r2_accuracy: 0.9049 - val_r3_accuracy: 0.5025\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 1.3316 - r1_loss: 0.6052 - r2_loss: 0.1990 - r3_loss: 0.6917 - r1_accuracy: 0.6575 - r2_accuracy: 0.9138 - r3_accuracy: 0.5191 - val_loss: 1.3195 - val_r1_loss: 0.5882 - val_r2_loss: 0.2126 - val_r3_loss: 0.6943 - val_r1_accuracy: 0.6793 - val_r2_accuracy: 0.9056 - val_r3_accuracy: 0.5026\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 1.3038 - r1_loss: 0.5775 - r2_loss: 0.1980 - r3_loss: 0.6918 - r1_accuracy: 0.6877 - r2_accuracy: 0.9141 - r3_accuracy: 0.5187 - val_loss: 1.2901 - val_r1_loss: 0.5589 - val_r2_loss: 0.2126 - val_r3_loss: 0.6942 - val_r1_accuracy: 0.7062 - val_r2_accuracy: 0.9063 - val_r3_accuracy: 0.5053\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 1.2724 - r1_loss: 0.5466 - r2_loss: 0.1995 - r3_loss: 0.6915 - r1_accuracy: 0.7173 - r2_accuracy: 0.9138 - r3_accuracy: 0.5213 - val_loss: 1.2613 - val_r1_loss: 0.5308 - val_r2_loss: 0.2100 - val_r3_loss: 0.6943 - val_r1_accuracy: 0.7302 - val_r2_accuracy: 0.9063 - val_r3_accuracy: 0.5029\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 1.2462 - r1_loss: 0.5207 - r2_loss: 0.1979 - r3_loss: 0.6916 - r1_accuracy: 0.7370 - r2_accuracy: 0.9140 - r3_accuracy: 0.5193 - val_loss: 1.2380 - val_r1_loss: 0.5072 - val_r2_loss: 0.2120 - val_r3_loss: 0.6944 - val_r1_accuracy: 0.7489 - val_r2_accuracy: 0.9051 - val_r3_accuracy: 0.5045\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 3s 107ms/step - loss: 1.2198 - r1_loss: 0.4951 - r2_loss: 0.1962 - r3_loss: 0.6911 - r1_accuracy: 0.7579 - r2_accuracy: 0.9144 - r3_accuracy: 0.5237 - val_loss: 1.2135 - val_r1_loss: 0.4829 - val_r2_loss: 0.2107 - val_r3_loss: 0.6946 - val_r1_accuracy: 0.7681 - val_r2_accuracy: 0.9063 - val_r3_accuracy: 0.5027\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 1.1943 - r1_loss: 0.4696 - r2_loss: 0.1968 - r3_loss: 0.6911 - r1_accuracy: 0.7750 - r2_accuracy: 0.9150 - r3_accuracy: 0.5238 - val_loss: 1.1885 - val_r1_loss: 0.4586 - val_r2_loss: 0.2078 - val_r3_loss: 0.6944 - val_r1_accuracy: 0.7836 - val_r2_accuracy: 0.9075 - val_r3_accuracy: 0.5043\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 3s 106ms/step - loss: 1.1713 - r1_loss: 0.4469 - r2_loss: 0.1953 - r3_loss: 0.6913 - r1_accuracy: 0.7884 - r2_accuracy: 0.9153 - r3_accuracy: 0.5216 - val_loss: 1.1667 - val_r1_loss: 0.4372 - val_r2_loss: 0.2079 - val_r3_loss: 0.6943 - val_r1_accuracy: 0.7933 - val_r2_accuracy: 0.9079 - val_r3_accuracy: 0.5062\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 1.1496 - r1_loss: 0.4258 - r2_loss: 0.1942 - r3_loss: 0.6910 - r1_accuracy: 0.8017 - r2_accuracy: 0.9161 - r3_accuracy: 0.5229 - val_loss: 1.1449 - val_r1_loss: 0.4161 - val_r2_loss: 0.2056 - val_r3_loss: 0.6941 - val_r1_accuracy: 0.8047 - val_r2_accuracy: 0.9077 - val_r3_accuracy: 0.5063\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 1.1261 - r1_loss: 0.4024 - r2_loss: 0.1933 - r3_loss: 0.6913 - r1_accuracy: 0.8108 - r2_accuracy: 0.9171 - r3_accuracy: 0.5205 - val_loss: 1.1236 - val_r1_loss: 0.3948 - val_r2_loss: 0.2042 - val_r3_loss: 0.6946 - val_r1_accuracy: 0.8160 - val_r2_accuracy: 0.9112 - val_r3_accuracy: 0.5055\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 1.1005 - r1_loss: 0.3787 - r2_loss: 0.1892 - r3_loss: 0.6907 - r1_accuracy: 0.8252 - r2_accuracy: 0.9182 - r3_accuracy: 0.5229 - val_loss: 1.0994 - val_r1_loss: 0.3722 - val_r2_loss: 0.2005 - val_r3_loss: 0.6942 - val_r1_accuracy: 0.8274 - val_r2_accuracy: 0.9119 - val_r3_accuracy: 0.5070\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 1.0828 - r1_loss: 0.3609 - r2_loss: 0.1892 - r3_loss: 0.6907 - r1_accuracy: 0.8340 - r2_accuracy: 0.9179 - r3_accuracy: 0.5238 - val_loss: 1.0843 - val_r1_loss: 0.3562 - val_r2_loss: 0.2036 - val_r3_loss: 0.6946 - val_r1_accuracy: 0.8348 - val_r2_accuracy: 0.9104 - val_r3_accuracy: 0.5083\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 3s 105ms/step - loss: 1.0636 - r1_loss: 0.3419 - r2_loss: 0.1879 - r3_loss: 0.6911 - r1_accuracy: 0.8439 - r2_accuracy: 0.9189 - r3_accuracy: 0.5211 - val_loss: 1.0717 - val_r1_loss: 0.3446 - val_r2_loss: 0.1996 - val_r3_loss: 0.6945 - val_r1_accuracy: 0.8412 - val_r2_accuracy: 0.9134 - val_r3_accuracy: 0.5016\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 1.0508 - r1_loss: 0.3294 - r2_loss: 0.1881 - r3_loss: 0.6907 - r1_accuracy: 0.8494 - r2_accuracy: 0.9186 - r3_accuracy: 0.5246 - val_loss: 1.0582 - val_r1_loss: 0.3313 - val_r2_loss: 0.1972 - val_r3_loss: 0.6947 - val_r1_accuracy: 0.8466 - val_r2_accuracy: 0.9135 - val_r3_accuracy: 0.5047\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 1.0347 - r1_loss: 0.3138 - r2_loss: 0.1868 - r3_loss: 0.6907 - r1_accuracy: 0.8568 - r2_accuracy: 0.9188 - r3_accuracy: 0.5216 - val_loss: 1.0464 - val_r1_loss: 0.3203 - val_r2_loss: 0.1971 - val_r3_loss: 0.6942 - val_r1_accuracy: 0.8535 - val_r2_accuracy: 0.9121 - val_r3_accuracy: 0.5053\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 1.0249 - r1_loss: 0.3037 - r2_loss: 0.1866 - r3_loss: 0.6908 - r1_accuracy: 0.8621 - r2_accuracy: 0.9187 - r3_accuracy: 0.5222 - val_loss: 1.0371 - val_r1_loss: 0.3101 - val_r2_loss: 0.2009 - val_r3_loss: 0.6942 - val_r1_accuracy: 0.8576 - val_r2_accuracy: 0.9121 - val_r3_accuracy: 0.5058\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 1.0152 - r1_loss: 0.2945 - r2_loss: 0.1861 - r3_loss: 0.6905 - r1_accuracy: 0.8663 - r2_accuracy: 0.9187 - r3_accuracy: 0.5240 - val_loss: 1.0264 - val_r1_loss: 0.3001 - val_r2_loss: 0.1961 - val_r3_loss: 0.6946 - val_r1_accuracy: 0.8630 - val_r2_accuracy: 0.9147 - val_r3_accuracy: 0.5021\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 1.0025 - r1_loss: 0.2833 - r2_loss: 0.1813 - r3_loss: 0.6901 - r1_accuracy: 0.8727 - r2_accuracy: 0.9215 - r3_accuracy: 0.5255 - val_loss: 1.0178 - val_r1_loss: 0.2917 - val_r2_loss: 0.1971 - val_r3_loss: 0.6944 - val_r1_accuracy: 0.8657 - val_r2_accuracy: 0.9132 - val_r3_accuracy: 0.5036\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9936 - r1_loss: 0.2752 - r2_loss: 0.1798 - r3_loss: 0.6900 - r1_accuracy: 0.8770 - r2_accuracy: 0.9211 - r3_accuracy: 0.5243 - val_loss: 1.0099 - val_r1_loss: 0.2852 - val_r2_loss: 0.1915 - val_r3_loss: 0.6945 - val_r1_accuracy: 0.8697 - val_r2_accuracy: 0.9162 - val_r3_accuracy: 0.5047\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9854 - r1_loss: 0.2670 - r2_loss: 0.1815 - r3_loss: 0.6899 - r1_accuracy: 0.8804 - r2_accuracy: 0.9218 - r3_accuracy: 0.5263 - val_loss: 1.0017 - val_r1_loss: 0.2774 - val_r2_loss: 0.1915 - val_r3_loss: 0.6942 - val_r1_accuracy: 0.8734 - val_r2_accuracy: 0.9155 - val_r3_accuracy: 0.5064\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9764 - r1_loss: 0.2589 - r2_loss: 0.1786 - r3_loss: 0.6896 - r1_accuracy: 0.8841 - r2_accuracy: 0.9229 - r3_accuracy: 0.5270 - val_loss: 0.9962 - val_r1_loss: 0.2717 - val_r2_loss: 0.1937 - val_r3_loss: 0.6943 - val_r1_accuracy: 0.8758 - val_r2_accuracy: 0.9138 - val_r3_accuracy: 0.5078\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9687 - r1_loss: 0.2517 - r2_loss: 0.1789 - r3_loss: 0.6893 - r1_accuracy: 0.8885 - r2_accuracy: 0.9230 - r3_accuracy: 0.5263 - val_loss: 0.9890 - val_r1_loss: 0.2653 - val_r2_loss: 0.1883 - val_r3_loss: 0.6945 - val_r1_accuracy: 0.8793 - val_r2_accuracy: 0.9175 - val_r3_accuracy: 0.5058\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9608 - r1_loss: 0.2450 - r2_loss: 0.1751 - r3_loss: 0.6892 - r1_accuracy: 0.8905 - r2_accuracy: 0.9254 - r3_accuracy: 0.5268 - val_loss: 0.9789 - val_r1_loss: 0.2565 - val_r2_loss: 0.1861 - val_r3_loss: 0.6942 - val_r1_accuracy: 0.8823 - val_r2_accuracy: 0.9177 - val_r3_accuracy: 0.5081\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9544 - r1_loss: 0.2392 - r2_loss: 0.1744 - r3_loss: 0.6891 - r1_accuracy: 0.8945 - r2_accuracy: 0.9256 - r3_accuracy: 0.5295 - val_loss: 0.9781 - val_r1_loss: 0.2559 - val_r2_loss: 0.1851 - val_r3_loss: 0.6944 - val_r1_accuracy: 0.8843 - val_r2_accuracy: 0.9193 - val_r3_accuracy: 0.5067\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.9482 - r1_loss: 0.2342 - r2_loss: 0.1706 - r3_loss: 0.6886 - r1_accuracy: 0.8961 - r2_accuracy: 0.9268 - r3_accuracy: 0.5302 - val_loss: 0.9674 - val_r1_loss: 0.2461 - val_r2_loss: 0.1837 - val_r3_loss: 0.6939 - val_r1_accuracy: 0.8885 - val_r2_accuracy: 0.9199 - val_r3_accuracy: 0.5086\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.9422 - r1_loss: 0.2281 - r2_loss: 0.1717 - r3_loss: 0.6888 - r1_accuracy: 0.8988 - r2_accuracy: 0.9263 - r3_accuracy: 0.5289 - val_loss: 0.9640 - val_r1_loss: 0.2433 - val_r2_loss: 0.1830 - val_r3_loss: 0.6937 - val_r1_accuracy: 0.8906 - val_r2_accuracy: 0.9195 - val_r3_accuracy: 0.5088\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.9375 - r1_loss: 0.2239 - r2_loss: 0.1689 - r3_loss: 0.6886 - r1_accuracy: 0.9011 - r2_accuracy: 0.9268 - r3_accuracy: 0.5312 - val_loss: 0.9582 - val_r1_loss: 0.2379 - val_r2_loss: 0.1809 - val_r3_loss: 0.6935 - val_r1_accuracy: 0.8929 - val_r2_accuracy: 0.9205 - val_r3_accuracy: 0.5135\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.7551 - r1_loss: 0.2175 - r2_loss: 0.1672 - r3_loss: 0.6880 - r1_accuracy: 0.9046 - r2_accuracy: 0.9287 - r3_accuracy: 0.5338 - val_loss: 0.7660 - val_r1_loss: 0.2366 - val_r2_loss: 0.1776 - val_r3_loss: 0.6936 - val_r1_accuracy: 0.8933 - val_r2_accuracy: 0.9209 - val_r3_accuracy: 0.5128\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.7530 - r1_loss: 0.2182 - r2_loss: 0.1669 - r3_loss: 0.6874 - r1_accuracy: 0.9043 - r2_accuracy: 0.9280 - r3_accuracy: 0.5351 - val_loss: 0.7639 - val_r1_loss: 0.2353 - val_r2_loss: 0.1777 - val_r3_loss: 0.6935 - val_r1_accuracy: 0.8942 - val_r2_accuracy: 0.9227 - val_r3_accuracy: 0.5114\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.7511 - r1_loss: 0.2141 - r2_loss: 0.1638 - r3_loss: 0.6870 - r1_accuracy: 0.9060 - r2_accuracy: 0.9301 - r3_accuracy: 0.5347 - val_loss: 0.7627 - val_r1_loss: 0.2358 - val_r2_loss: 0.1730 - val_r3_loss: 0.6931 - val_r1_accuracy: 0.8924 - val_r2_accuracy: 0.9236 - val_r3_accuracy: 0.5123\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.7496 - r1_loss: 0.2136 - r2_loss: 0.1621 - r3_loss: 0.6869 - r1_accuracy: 0.9073 - r2_accuracy: 0.9299 - r3_accuracy: 0.5366 - val_loss: 0.7617 - val_r1_loss: 0.2357 - val_r2_loss: 0.1711 - val_r3_loss: 0.6936 - val_r1_accuracy: 0.8930 - val_r2_accuracy: 0.9267 - val_r3_accuracy: 0.5121\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.7477 - r1_loss: 0.2086 - r2_loss: 0.1592 - r3_loss: 0.6866 - r1_accuracy: 0.9091 - r2_accuracy: 0.9323 - r3_accuracy: 0.5357 - val_loss: 0.7604 - val_r1_loss: 0.2315 - val_r2_loss: 0.1701 - val_r3_loss: 0.6935 - val_r1_accuracy: 0.8961 - val_r2_accuracy: 0.9247 - val_r3_accuracy: 0.5129\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.7466 - r1_loss: 0.2116 - r2_loss: 0.1578 - r3_loss: 0.6862 - r1_accuracy: 0.9074 - r2_accuracy: 0.9332 - r3_accuracy: 0.5371 - val_loss: 0.7580 - val_r1_loss: 0.2301 - val_r2_loss: 0.1675 - val_r3_loss: 0.6929 - val_r1_accuracy: 0.8964 - val_r2_accuracy: 0.9286 - val_r3_accuracy: 0.5166\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.7449 - r1_loss: 0.2088 - r2_loss: 0.1558 - r3_loss: 0.6853 - r1_accuracy: 0.9084 - r2_accuracy: 0.9338 - r3_accuracy: 0.5410 - val_loss: 0.7578 - val_r1_loss: 0.2300 - val_r2_loss: 0.1671 - val_r3_loss: 0.6928 - val_r1_accuracy: 0.8960 - val_r2_accuracy: 0.9275 - val_r3_accuracy: 0.5206\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.7443 - r1_loss: 0.2090 - r2_loss: 0.1546 - r3_loss: 0.6853 - r1_accuracy: 0.9090 - r2_accuracy: 0.9342 - r3_accuracy: 0.5391 - val_loss: 0.7579 - val_r1_loss: 0.2321 - val_r2_loss: 0.1652 - val_r3_loss: 0.6932 - val_r1_accuracy: 0.8946 - val_r2_accuracy: 0.9279 - val_r3_accuracy: 0.5158\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.7431 - r1_loss: 0.2094 - r2_loss: 0.1522 - r3_loss: 0.6847 - r1_accuracy: 0.9086 - r2_accuracy: 0.9347 - r3_accuracy: 0.5432 - val_loss: 0.7561 - val_r1_loss: 0.2278 - val_r2_loss: 0.1615 - val_r3_loss: 0.6931 - val_r1_accuracy: 0.8975 - val_r2_accuracy: 0.9296 - val_r3_accuracy: 0.5173\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.7413 - r1_loss: 0.2071 - r2_loss: 0.1506 - r3_loss: 0.6840 - r1_accuracy: 0.9097 - r2_accuracy: 0.9366 - r3_accuracy: 0.5439 - val_loss: 0.7548 - val_r1_loss: 0.2260 - val_r2_loss: 0.1653 - val_r3_loss: 0.6920 - val_r1_accuracy: 0.8976 - val_r2_accuracy: 0.9284 - val_r3_accuracy: 0.5185\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.7403 - r1_loss: 0.2075 - r2_loss: 0.1487 - r3_loss: 0.6835 - r1_accuracy: 0.9090 - r2_accuracy: 0.9367 - r3_accuracy: 0.5447 - val_loss: 0.7536 - val_r1_loss: 0.2273 - val_r2_loss: 0.1633 - val_r3_loss: 0.6914 - val_r1_accuracy: 0.8981 - val_r2_accuracy: 0.9285 - val_r3_accuracy: 0.5199\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.7381 - r1_loss: 0.2068 - r2_loss: 0.1478 - r3_loss: 0.6820 - r1_accuracy: 0.9097 - r2_accuracy: 0.9377 - r3_accuracy: 0.5481 - val_loss: 0.7522 - val_r1_loss: 0.2268 - val_r2_loss: 0.1603 - val_r3_loss: 0.6909 - val_r1_accuracy: 0.8971 - val_r2_accuracy: 0.9296 - val_r3_accuracy: 0.5244\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 3s 110ms/step - loss: 0.7363 - r1_loss: 0.2041 - r2_loss: 0.1468 - r3_loss: 0.6813 - r1_accuracy: 0.9117 - r2_accuracy: 0.9378 - r3_accuracy: 0.5489 - val_loss: 0.7506 - val_r1_loss: 0.2273 - val_r2_loss: 0.1566 - val_r3_loss: 0.6903 - val_r1_accuracy: 0.8988 - val_r2_accuracy: 0.9311 - val_r3_accuracy: 0.5252\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.7340 - r1_loss: 0.2038 - r2_loss: 0.1449 - r3_loss: 0.6798 - r1_accuracy: 0.9106 - r2_accuracy: 0.9387 - r3_accuracy: 0.5530 - val_loss: 0.7490 - val_r1_loss: 0.2251 - val_r2_loss: 0.1575 - val_r3_loss: 0.6894 - val_r1_accuracy: 0.8990 - val_r2_accuracy: 0.9320 - val_r3_accuracy: 0.5259\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 3s 110ms/step - loss: 0.7337 - r1_loss: 0.2022 - r2_loss: 0.1443 - r3_loss: 0.6797 - r1_accuracy: 0.9116 - r2_accuracy: 0.9387 - r3_accuracy: 0.5517 - val_loss: 0.7478 - val_r1_loss: 0.2265 - val_r2_loss: 0.1560 - val_r3_loss: 0.6880 - val_r1_accuracy: 0.8978 - val_r2_accuracy: 0.9319 - val_r3_accuracy: 0.5304\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 3s 110ms/step - loss: 0.7324 - r1_loss: 0.2050 - r2_loss: 0.1399 - r3_loss: 0.6785 - r1_accuracy: 0.9109 - r2_accuracy: 0.9408 - r3_accuracy: 0.5545 - val_loss: 0.7470 - val_r1_loss: 0.2249 - val_r2_loss: 0.1537 - val_r3_loss: 0.6880 - val_r1_accuracy: 0.8980 - val_r2_accuracy: 0.9352 - val_r3_accuracy: 0.5324\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 3s 110ms/step - loss: 0.7304 - r1_loss: 0.2029 - r2_loss: 0.1420 - r3_loss: 0.6772 - r1_accuracy: 0.9114 - r2_accuracy: 0.9405 - r3_accuracy: 0.5561 - val_loss: 0.7436 - val_r1_loss: 0.2198 - val_r2_loss: 0.1524 - val_r3_loss: 0.6861 - val_r1_accuracy: 0.9022 - val_r2_accuracy: 0.9340 - val_r3_accuracy: 0.5368\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.7284 - r1_loss: 0.2007 - r2_loss: 0.1418 - r3_loss: 0.6760 - r1_accuracy: 0.9118 - r2_accuracy: 0.9395 - r3_accuracy: 0.5585 - val_loss: 0.7423 - val_r1_loss: 0.2218 - val_r2_loss: 0.1495 - val_r3_loss: 0.6853 - val_r1_accuracy: 0.9004 - val_r2_accuracy: 0.9362 - val_r3_accuracy: 0.5367\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.7270 - r1_loss: 0.2021 - r2_loss: 0.1393 - r3_loss: 0.6745 - r1_accuracy: 0.9115 - r2_accuracy: 0.9414 - r3_accuracy: 0.5634 - val_loss: 0.7421 - val_r1_loss: 0.2224 - val_r2_loss: 0.1497 - val_r3_loss: 0.6848 - val_r1_accuracy: 0.9009 - val_r2_accuracy: 0.9353 - val_r3_accuracy: 0.5360\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 3s 110ms/step - loss: 0.7230 - r1_loss: 0.1971 - r2_loss: 0.1374 - r3_loss: 0.6723 - r1_accuracy: 0.9141 - r2_accuracy: 0.9417 - r3_accuracy: 0.5670 - val_loss: 0.7376 - val_r1_loss: 0.2194 - val_r2_loss: 0.1484 - val_r3_loss: 0.6817 - val_r1_accuracy: 0.9030 - val_r2_accuracy: 0.9354 - val_r3_accuracy: 0.5485\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.7204 - r1_loss: 0.1987 - r2_loss: 0.1362 - r3_loss: 0.6699 - r1_accuracy: 0.9130 - r2_accuracy: 0.9425 - r3_accuracy: 0.5704 - val_loss: 0.7350 - val_r1_loss: 0.2194 - val_r2_loss: 0.1484 - val_r3_loss: 0.6796 - val_r1_accuracy: 0.9024 - val_r2_accuracy: 0.9361 - val_r3_accuracy: 0.5500\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 3s 110ms/step - loss: 0.7184 - r1_loss: 0.1986 - r2_loss: 0.1365 - r3_loss: 0.6682 - r1_accuracy: 0.9128 - r2_accuracy: 0.9427 - r3_accuracy: 0.5725 - val_loss: 0.7321 - val_r1_loss: 0.2193 - val_r2_loss: 0.1486 - val_r3_loss: 0.6768 - val_r1_accuracy: 0.9008 - val_r2_accuracy: 0.9358 - val_r3_accuracy: 0.5551\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.7139 - r1_loss: 0.1961 - r2_loss: 0.1349 - r3_loss: 0.6644 - r1_accuracy: 0.9145 - r2_accuracy: 0.9429 - r3_accuracy: 0.5757 - val_loss: 0.7269 - val_r1_loss: 0.2177 - val_r2_loss: 0.1447 - val_r3_loss: 0.6725 - val_r1_accuracy: 0.9026 - val_r2_accuracy: 0.9381 - val_r3_accuracy: 0.5628\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.7110 - r1_loss: 0.1992 - r2_loss: 0.1335 - r3_loss: 0.6614 - r1_accuracy: 0.9127 - r2_accuracy: 0.9437 - r3_accuracy: 0.5838 - val_loss: 0.7223 - val_r1_loss: 0.2183 - val_r2_loss: 0.1452 - val_r3_loss: 0.6680 - val_r1_accuracy: 0.9029 - val_r2_accuracy: 0.9379 - val_r3_accuracy: 0.5674\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.7073 - r1_loss: 0.1959 - r2_loss: 0.1339 - r3_loss: 0.6578 - r1_accuracy: 0.9140 - r2_accuracy: 0.9434 - r3_accuracy: 0.5887 - val_loss: 0.7167 - val_r1_loss: 0.2147 - val_r2_loss: 0.1444 - val_r3_loss: 0.6627 - val_r1_accuracy: 0.9029 - val_r2_accuracy: 0.9385 - val_r3_accuracy: 0.5765\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.7008 - r1_loss: 0.1969 - r2_loss: 0.1321 - r3_loss: 0.6521 - r1_accuracy: 0.9137 - r2_accuracy: 0.9443 - r3_accuracy: 0.5947 - val_loss: 0.7115 - val_r1_loss: 0.2165 - val_r2_loss: 0.1422 - val_r3_loss: 0.6583 - val_r1_accuracy: 0.9017 - val_r2_accuracy: 0.9381 - val_r3_accuracy: 0.5864\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.6948 - r1_loss: 0.1984 - r2_loss: 0.1329 - r3_loss: 0.6460 - r1_accuracy: 0.9128 - r2_accuracy: 0.9433 - r3_accuracy: 0.6044 - val_loss: 0.7048 - val_r1_loss: 0.2174 - val_r2_loss: 0.1440 - val_r3_loss: 0.6515 - val_r1_accuracy: 0.9021 - val_r2_accuracy: 0.9389 - val_r3_accuracy: 0.5943\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.6902 - r1_loss: 0.1968 - r2_loss: 0.1304 - r3_loss: 0.6411 - r1_accuracy: 0.9144 - r2_accuracy: 0.9447 - r3_accuracy: 0.6128 - val_loss: 0.6986 - val_r1_loss: 0.2165 - val_r2_loss: 0.1414 - val_r3_loss: 0.6448 - val_r1_accuracy: 0.9025 - val_r2_accuracy: 0.9398 - val_r3_accuracy: 0.6055\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.6825 - r1_loss: 0.1972 - r2_loss: 0.1299 - r3_loss: 0.6339 - r1_accuracy: 0.9131 - r2_accuracy: 0.9453 - r3_accuracy: 0.6228 - val_loss: 0.6929 - val_r1_loss: 0.2160 - val_r2_loss: 0.1442 - val_r3_loss: 0.6395 - val_r1_accuracy: 0.9033 - val_r2_accuracy: 0.9380 - val_r3_accuracy: 0.6147\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.6760 - r1_loss: 0.1974 - r2_loss: 0.1267 - r3_loss: 0.6277 - r1_accuracy: 0.9128 - r2_accuracy: 0.9467 - r3_accuracy: 0.6305 - val_loss: 0.6852 - val_r1_loss: 0.2144 - val_r2_loss: 0.1416 - val_r3_loss: 0.6323 - val_r1_accuracy: 0.9038 - val_r2_accuracy: 0.9390 - val_r3_accuracy: 0.6234\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.6701 - r1_loss: 0.1978 - r2_loss: 0.1293 - r3_loss: 0.6218 - r1_accuracy: 0.9130 - r2_accuracy: 0.9450 - r3_accuracy: 0.6369 - val_loss: 0.6811 - val_r1_loss: 0.2188 - val_r2_loss: 0.1406 - val_r3_loss: 0.6280 - val_r1_accuracy: 0.9010 - val_r2_accuracy: 0.9394 - val_r3_accuracy: 0.6285\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.6650 - r1_loss: 0.1979 - r2_loss: 0.1271 - r3_loss: 0.6165 - r1_accuracy: 0.9131 - r2_accuracy: 0.9459 - r3_accuracy: 0.6455 - val_loss: 0.6754 - val_r1_loss: 0.2167 - val_r2_loss: 0.1416 - val_r3_loss: 0.6221 - val_r1_accuracy: 0.9028 - val_r2_accuracy: 0.9399 - val_r3_accuracy: 0.6358\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.6578 - r1_loss: 0.1973 - r2_loss: 0.1271 - r3_loss: 0.6093 - r1_accuracy: 0.9136 - r2_accuracy: 0.9460 - r3_accuracy: 0.6529 - val_loss: 0.6705 - val_r1_loss: 0.2192 - val_r2_loss: 0.1390 - val_r3_loss: 0.6169 - val_r1_accuracy: 0.9023 - val_r2_accuracy: 0.9405 - val_r3_accuracy: 0.6443\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.6524 - r1_loss: 0.1984 - r2_loss: 0.1250 - r3_loss: 0.6043 - r1_accuracy: 0.9132 - r2_accuracy: 0.9466 - r3_accuracy: 0.6582 - val_loss: 0.6634 - val_r1_loss: 0.2182 - val_r2_loss: 0.1366 - val_r3_loss: 0.6106 - val_r1_accuracy: 0.9032 - val_r2_accuracy: 0.9413 - val_r3_accuracy: 0.6513\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 0.6470 - r1_loss: 0.2003 - r2_loss: 0.1255 - r3_loss: 0.5985 - r1_accuracy: 0.9115 - r2_accuracy: 0.9471 - r3_accuracy: 0.6659 - val_loss: 0.6577 - val_r1_loss: 0.2209 - val_r2_loss: 0.1349 - val_r3_loss: 0.6047 - val_r1_accuracy: 0.9010 - val_r2_accuracy: 0.9427 - val_r3_accuracy: 0.6568\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 0.6393 - r1_loss: 0.1990 - r2_loss: 0.1236 - r3_loss: 0.5912 - r1_accuracy: 0.9121 - r2_accuracy: 0.9469 - r3_accuracy: 0.6728 - val_loss: 0.6515 - val_r1_loss: 0.2184 - val_r2_loss: 0.1338 - val_r3_loss: 0.5990 - val_r1_accuracy: 0.9025 - val_r2_accuracy: 0.9430 - val_r3_accuracy: 0.6644\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.6331 - r1_loss: 0.1994 - r2_loss: 0.1231 - r3_loss: 0.5847 - r1_accuracy: 0.9122 - r2_accuracy: 0.9476 - r3_accuracy: 0.6795 - val_loss: 0.6434 - val_r1_loss: 0.2181 - val_r2_loss: 0.1314 - val_r3_loss: 0.5908 - val_r1_accuracy: 0.9028 - val_r2_accuracy: 0.9438 - val_r3_accuracy: 0.6713\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.6252 - r1_loss: 0.1982 - r2_loss: 0.1212 - r3_loss: 0.5776 - r1_accuracy: 0.9132 - r2_accuracy: 0.9489 - r3_accuracy: 0.6842 - val_loss: 0.6357 - val_r1_loss: 0.2206 - val_r2_loss: 0.1327 - val_r3_loss: 0.5829 - val_r1_accuracy: 0.9015 - val_r2_accuracy: 0.9435 - val_r3_accuracy: 0.6767\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 0.6185 - r1_loss: 0.1993 - r2_loss: 0.1217 - r3_loss: 0.5708 - r1_accuracy: 0.9123 - r2_accuracy: 0.9482 - r3_accuracy: 0.6911 - val_loss: 0.6294 - val_r1_loss: 0.2198 - val_r2_loss: 0.1323 - val_r3_loss: 0.5770 - val_r1_accuracy: 0.9014 - val_r2_accuracy: 0.9430 - val_r3_accuracy: 0.6847\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.6078 - r1_loss: 0.1992 - r2_loss: 0.1205 - r3_loss: 0.5603 - r1_accuracy: 0.9122 - r2_accuracy: 0.9492 - r3_accuracy: 0.7012 - val_loss: 0.6192 - val_r1_loss: 0.2216 - val_r2_loss: 0.1285 - val_r3_loss: 0.5670 - val_r1_accuracy: 0.9008 - val_r2_accuracy: 0.9452 - val_r3_accuracy: 0.6951\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.6019 - r1_loss: 0.2028 - r2_loss: 0.1178 - r3_loss: 0.5542 - r1_accuracy: 0.9113 - r2_accuracy: 0.9497 - r3_accuracy: 0.7052 - val_loss: 0.6129 - val_r1_loss: 0.2196 - val_r2_loss: 0.1290 - val_r3_loss: 0.5611 - val_r1_accuracy: 0.9018 - val_r2_accuracy: 0.9443 - val_r3_accuracy: 0.6992\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.5955 - r1_loss: 0.2018 - r2_loss: 0.1192 - r3_loss: 0.5476 - r1_accuracy: 0.9119 - r2_accuracy: 0.9496 - r3_accuracy: 0.7103 - val_loss: 0.6054 - val_r1_loss: 0.2195 - val_r2_loss: 0.1291 - val_r3_loss: 0.5534 - val_r1_accuracy: 0.9014 - val_r2_accuracy: 0.9458 - val_r3_accuracy: 0.7038\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.5868 - r1_loss: 0.2018 - r2_loss: 0.1186 - r3_loss: 0.5390 - r1_accuracy: 0.9111 - r2_accuracy: 0.9503 - r3_accuracy: 0.7178 - val_loss: 0.5994 - val_r1_loss: 0.2196 - val_r2_loss: 0.1288 - val_r3_loss: 0.5474 - val_r1_accuracy: 0.9015 - val_r2_accuracy: 0.9451 - val_r3_accuracy: 0.7109\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.5789 - r1_loss: 0.2026 - r2_loss: 0.1180 - r3_loss: 0.5311 - r1_accuracy: 0.9106 - r2_accuracy: 0.9501 - r3_accuracy: 0.7234 - val_loss: 0.5909 - val_r1_loss: 0.2211 - val_r2_loss: 0.1289 - val_r3_loss: 0.5387 - val_r1_accuracy: 0.9022 - val_r2_accuracy: 0.9440 - val_r3_accuracy: 0.7164\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.5750 - r1_loss: 0.2044 - r2_loss: 0.1185 - r3_loss: 0.5260 - r1_accuracy: 0.9099 - r2_accuracy: 0.9496 - r3_accuracy: 0.7281 - val_loss: 0.5848 - val_r1_loss: 0.2206 - val_r2_loss: 0.1276 - val_r3_loss: 0.5320 - val_r1_accuracy: 0.9025 - val_r2_accuracy: 0.9452 - val_r3_accuracy: 0.7199\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.5657 - r1_loss: 0.2025 - r2_loss: 0.1191 - r3_loss: 0.5170 - r1_accuracy: 0.9117 - r2_accuracy: 0.9492 - r3_accuracy: 0.7346 - val_loss: 0.5790 - val_r1_loss: 0.2203 - val_r2_loss: 0.1283 - val_r3_loss: 0.5262 - val_r1_accuracy: 0.9013 - val_r2_accuracy: 0.9443 - val_r3_accuracy: 0.7238\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.5577 - r1_loss: 0.2052 - r2_loss: 0.1162 - r3_loss: 0.5092 - r1_accuracy: 0.9095 - r2_accuracy: 0.9500 - r3_accuracy: 0.7404 - val_loss: 0.5705 - val_r1_loss: 0.2220 - val_r2_loss: 0.1258 - val_r3_loss: 0.5180 - val_r1_accuracy: 0.9004 - val_r2_accuracy: 0.9462 - val_r3_accuracy: 0.7304\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.5497 - r1_loss: 0.2059 - r2_loss: 0.1157 - r3_loss: 0.5005 - r1_accuracy: 0.9093 - r2_accuracy: 0.9511 - r3_accuracy: 0.7449 - val_loss: 0.5640 - val_r1_loss: 0.2234 - val_r2_loss: 0.1270 - val_r3_loss: 0.5104 - val_r1_accuracy: 0.9001 - val_r2_accuracy: 0.9449 - val_r3_accuracy: 0.7359\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.5411 - r1_loss: 0.2056 - r2_loss: 0.1159 - r3_loss: 0.4923 - r1_accuracy: 0.9089 - r2_accuracy: 0.9504 - r3_accuracy: 0.7521 - val_loss: 0.5560 - val_r1_loss: 0.2224 - val_r2_loss: 0.1258 - val_r3_loss: 0.5032 - val_r1_accuracy: 0.9001 - val_r2_accuracy: 0.9458 - val_r3_accuracy: 0.7418\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.5337 - r1_loss: 0.2058 - r2_loss: 0.1162 - r3_loss: 0.4846 - r1_accuracy: 0.9091 - r2_accuracy: 0.9511 - r3_accuracy: 0.7574 - val_loss: 0.5489 - val_r1_loss: 0.2227 - val_r2_loss: 0.1276 - val_r3_loss: 0.4955 - val_r1_accuracy: 0.9004 - val_r2_accuracy: 0.9449 - val_r3_accuracy: 0.7472\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 0.5256 - r1_loss: 0.2055 - r2_loss: 0.1161 - r3_loss: 0.4769 - r1_accuracy: 0.9095 - r2_accuracy: 0.9505 - r3_accuracy: 0.7617 - val_loss: 0.5428 - val_r1_loss: 0.2220 - val_r2_loss: 0.1263 - val_r3_loss: 0.4901 - val_r1_accuracy: 0.9000 - val_r2_accuracy: 0.9449 - val_r3_accuracy: 0.7530\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.5186 - r1_loss: 0.2072 - r2_loss: 0.1141 - r3_loss: 0.4698 - r1_accuracy: 0.9086 - r2_accuracy: 0.9510 - r3_accuracy: 0.7669 - val_loss: 0.5347 - val_r1_loss: 0.2242 - val_r2_loss: 0.1266 - val_r3_loss: 0.4816 - val_r1_accuracy: 0.8989 - val_r2_accuracy: 0.9464 - val_r3_accuracy: 0.7570\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.5131 - r1_loss: 0.2079 - r2_loss: 0.1152 - r3_loss: 0.4639 - r1_accuracy: 0.9081 - r2_accuracy: 0.9510 - r3_accuracy: 0.7728 - val_loss: 0.5293 - val_r1_loss: 0.2213 - val_r2_loss: 0.1250 - val_r3_loss: 0.4767 - val_r1_accuracy: 0.9007 - val_r2_accuracy: 0.9461 - val_r3_accuracy: 0.7587\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.5073 - r1_loss: 0.2064 - r2_loss: 0.1155 - r3_loss: 0.4578 - r1_accuracy: 0.9095 - r2_accuracy: 0.9510 - r3_accuracy: 0.7734 - val_loss: 0.5226 - val_r1_loss: 0.2206 - val_r2_loss: 0.1256 - val_r3_loss: 0.4695 - val_r1_accuracy: 0.9012 - val_r2_accuracy: 0.9454 - val_r3_accuracy: 0.7664\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.5001 - r1_loss: 0.2075 - r2_loss: 0.1164 - r3_loss: 0.4509 - r1_accuracy: 0.9083 - r2_accuracy: 0.9501 - r3_accuracy: 0.7793 - val_loss: 0.5162 - val_r1_loss: 0.2240 - val_r2_loss: 0.1240 - val_r3_loss: 0.4633 - val_r1_accuracy: 0.9006 - val_r2_accuracy: 0.9467 - val_r3_accuracy: 0.7670\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.4952 - r1_loss: 0.2061 - r2_loss: 0.1141 - r3_loss: 0.4461 - r1_accuracy: 0.9098 - r2_accuracy: 0.9513 - r3_accuracy: 0.7829 - val_loss: 0.5106 - val_r1_loss: 0.2170 - val_r2_loss: 0.1240 - val_r3_loss: 0.4585 - val_r1_accuracy: 0.9038 - val_r2_accuracy: 0.9463 - val_r3_accuracy: 0.7711\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.4878 - r1_loss: 0.2083 - r2_loss: 0.1152 - r3_loss: 0.4386 - r1_accuracy: 0.9083 - r2_accuracy: 0.9513 - r3_accuracy: 0.7869 - val_loss: 0.5049 - val_r1_loss: 0.2220 - val_r2_loss: 0.1223 - val_r3_loss: 0.4526 - val_r1_accuracy: 0.9011 - val_r2_accuracy: 0.9470 - val_r3_accuracy: 0.7754\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.4829 - r1_loss: 0.2073 - r2_loss: 0.1146 - r3_loss: 0.4340 - r1_accuracy: 0.9086 - r2_accuracy: 0.9505 - r3_accuracy: 0.7906 - val_loss: 0.4998 - val_r1_loss: 0.2214 - val_r2_loss: 0.1224 - val_r3_loss: 0.4476 - val_r1_accuracy: 0.9004 - val_r2_accuracy: 0.9465 - val_r3_accuracy: 0.7769\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 3s 107ms/step - loss: 0.4771 - r1_loss: 0.2048 - r2_loss: 0.1130 - r3_loss: 0.4288 - r1_accuracy: 0.9094 - r2_accuracy: 0.9520 - r3_accuracy: 0.7929 - val_loss: 0.4949 - val_r1_loss: 0.2189 - val_r2_loss: 0.1205 - val_r3_loss: 0.4433 - val_r1_accuracy: 0.9029 - val_r2_accuracy: 0.9478 - val_r3_accuracy: 0.7825\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 0.4705 - r1_loss: 0.2052 - r2_loss: 0.1140 - r3_loss: 0.4222 - r1_accuracy: 0.9100 - r2_accuracy: 0.9509 - r3_accuracy: 0.7972 - val_loss: 0.4902 - val_r1_loss: 0.2200 - val_r2_loss: 0.1229 - val_r3_loss: 0.4384 - val_r1_accuracy: 0.9017 - val_r2_accuracy: 0.9468 - val_r3_accuracy: 0.7834\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4646 - r1_loss: 0.2019 - r2_loss: 0.1129 - r3_loss: 0.4171 - r1_accuracy: 0.9107 - r2_accuracy: 0.9520 - r3_accuracy: 0.8002 - val_loss: 0.4846 - val_r1_loss: 0.2182 - val_r2_loss: 0.1215 - val_r3_loss: 0.4335 - val_r1_accuracy: 0.9029 - val_r2_accuracy: 0.9479 - val_r3_accuracy: 0.7878\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4564 - r1_loss: 0.2023 - r2_loss: 0.1133 - r3_loss: 0.4089 - r1_accuracy: 0.9115 - r2_accuracy: 0.9515 - r3_accuracy: 0.8041 - val_loss: 0.4796 - val_r1_loss: 0.2165 - val_r2_loss: 0.1205 - val_r3_loss: 0.4288 - val_r1_accuracy: 0.9022 - val_r2_accuracy: 0.9473 - val_r3_accuracy: 0.7898\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.4547 - r1_loss: 0.2047 - r2_loss: 0.1118 - r3_loss: 0.4075 - r1_accuracy: 0.9093 - r2_accuracy: 0.9522 - r3_accuracy: 0.8056 - val_loss: 0.4739 - val_r1_loss: 0.2145 - val_r2_loss: 0.1219 - val_r3_loss: 0.4239 - val_r1_accuracy: 0.9055 - val_r2_accuracy: 0.9472 - val_r3_accuracy: 0.7941\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4506 - r1_loss: 0.2024 - r2_loss: 0.1122 - r3_loss: 0.4030 - r1_accuracy: 0.9105 - r2_accuracy: 0.9520 - r3_accuracy: 0.8086 - val_loss: 0.4705 - val_r1_loss: 0.2185 - val_r2_loss: 0.1231 - val_r3_loss: 0.4189 - val_r1_accuracy: 0.9025 - val_r2_accuracy: 0.9468 - val_r3_accuracy: 0.7959\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4427 - r1_loss: 0.2031 - r2_loss: 0.1112 - r3_loss: 0.3952 - r1_accuracy: 0.9111 - r2_accuracy: 0.9530 - r3_accuracy: 0.8128 - val_loss: 0.4673 - val_r1_loss: 0.2168 - val_r2_loss: 0.1201 - val_r3_loss: 0.4165 - val_r1_accuracy: 0.9039 - val_r2_accuracy: 0.9479 - val_r3_accuracy: 0.7970\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.4397 - r1_loss: 0.2025 - r2_loss: 0.1129 - r3_loss: 0.3927 - r1_accuracy: 0.9121 - r2_accuracy: 0.9514 - r3_accuracy: 0.8146 - val_loss: 0.4595 - val_r1_loss: 0.2147 - val_r2_loss: 0.1205 - val_r3_loss: 0.4096 - val_r1_accuracy: 0.9050 - val_r2_accuracy: 0.9477 - val_r3_accuracy: 0.8009\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4318 - r1_loss: 0.2003 - r2_loss: 0.1104 - r3_loss: 0.3859 - r1_accuracy: 0.9125 - r2_accuracy: 0.9535 - r3_accuracy: 0.8183 - val_loss: 0.4552 - val_r1_loss: 0.2154 - val_r2_loss: 0.1171 - val_r3_loss: 0.4059 - val_r1_accuracy: 0.9040 - val_r2_accuracy: 0.9491 - val_r3_accuracy: 0.8051\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4285 - r1_loss: 0.2037 - r2_loss: 0.1103 - r3_loss: 0.3823 - r1_accuracy: 0.9102 - r2_accuracy: 0.9531 - r3_accuracy: 0.8212 - val_loss: 0.4484 - val_r1_loss: 0.2141 - val_r2_loss: 0.1181 - val_r3_loss: 0.3996 - val_r1_accuracy: 0.9034 - val_r2_accuracy: 0.9498 - val_r3_accuracy: 0.8070\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.4235 - r1_loss: 0.1990 - r2_loss: 0.1094 - r3_loss: 0.3778 - r1_accuracy: 0.9124 - r2_accuracy: 0.9536 - r3_accuracy: 0.8238 - val_loss: 0.4446 - val_r1_loss: 0.2126 - val_r2_loss: 0.1183 - val_r3_loss: 0.3956 - val_r1_accuracy: 0.9055 - val_r2_accuracy: 0.9495 - val_r3_accuracy: 0.8109\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4212 - r1_loss: 0.2015 - r2_loss: 0.1089 - r3_loss: 0.3756 - r1_accuracy: 0.9109 - r2_accuracy: 0.9533 - r3_accuracy: 0.8247 - val_loss: 0.4405 - val_r1_loss: 0.2120 - val_r2_loss: 0.1195 - val_r3_loss: 0.3921 - val_r1_accuracy: 0.9064 - val_r2_accuracy: 0.9481 - val_r3_accuracy: 0.8117\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4158 - r1_loss: 0.1979 - r2_loss: 0.1089 - r3_loss: 0.3705 - r1_accuracy: 0.9132 - r2_accuracy: 0.9535 - r3_accuracy: 0.8273 - val_loss: 0.4337 - val_r1_loss: 0.2097 - val_r2_loss: 0.1184 - val_r3_loss: 0.3855 - val_r1_accuracy: 0.9066 - val_r2_accuracy: 0.9497 - val_r3_accuracy: 0.8141\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4089 - r1_loss: 0.1979 - r2_loss: 0.1069 - r3_loss: 0.3643 - r1_accuracy: 0.9131 - r2_accuracy: 0.9546 - r3_accuracy: 0.8307 - val_loss: 0.4346 - val_r1_loss: 0.2116 - val_r2_loss: 0.1153 - val_r3_loss: 0.3867 - val_r1_accuracy: 0.9054 - val_r2_accuracy: 0.9493 - val_r3_accuracy: 0.8165\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.4054 - r1_loss: 0.1980 - r2_loss: 0.1061 - r3_loss: 0.3611 - r1_accuracy: 0.9142 - r2_accuracy: 0.9545 - r3_accuracy: 0.8323 - val_loss: 0.4272 - val_r1_loss: 0.2133 - val_r2_loss: 0.1149 - val_r3_loss: 0.3795 - val_r1_accuracy: 0.9048 - val_r2_accuracy: 0.9507 - val_r3_accuracy: 0.8193\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.3981 - r1_loss: 0.1956 - r2_loss: 0.1055 - r3_loss: 0.3546 - r1_accuracy: 0.9150 - r2_accuracy: 0.9550 - r3_accuracy: 0.8344 - val_loss: 0.4250 - val_r1_loss: 0.2120 - val_r2_loss: 0.1142 - val_r3_loss: 0.3779 - val_r1_accuracy: 0.9065 - val_r2_accuracy: 0.9507 - val_r3_accuracy: 0.8203\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.3974 - r1_loss: 0.1967 - r2_loss: 0.1052 - r3_loss: 0.3540 - r1_accuracy: 0.9131 - r2_accuracy: 0.9555 - r3_accuracy: 0.8362 - val_loss: 0.4205 - val_r1_loss: 0.2093 - val_r2_loss: 0.1131 - val_r3_loss: 0.3743 - val_r1_accuracy: 0.9076 - val_r2_accuracy: 0.9520 - val_r3_accuracy: 0.8213\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.3933 - r1_loss: 0.1961 - r2_loss: 0.1059 - r3_loss: 0.3496 - r1_accuracy: 0.9145 - r2_accuracy: 0.9547 - r3_accuracy: 0.8383 - val_loss: 0.4199 - val_r1_loss: 0.2095 - val_r2_loss: 0.1127 - val_r3_loss: 0.3732 - val_r1_accuracy: 0.9076 - val_r2_accuracy: 0.9521 - val_r3_accuracy: 0.8232\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.3872 - r1_loss: 0.1952 - r2_loss: 0.1039 - r3_loss: 0.3442 - r1_accuracy: 0.9145 - r2_accuracy: 0.9561 - r3_accuracy: 0.8418 - val_loss: 0.4166 - val_r1_loss: 0.2080 - val_r2_loss: 0.1108 - val_r3_loss: 0.3708 - val_r1_accuracy: 0.9074 - val_r2_accuracy: 0.9518 - val_r3_accuracy: 0.8243\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.3840 - r1_loss: 0.1951 - r2_loss: 0.1044 - r3_loss: 0.3413 - r1_accuracy: 0.9148 - r2_accuracy: 0.9558 - r3_accuracy: 0.8429 - val_loss: 0.4096 - val_r1_loss: 0.2058 - val_r2_loss: 0.1099 - val_r3_loss: 0.3646 - val_r1_accuracy: 0.9101 - val_r2_accuracy: 0.9525 - val_r3_accuracy: 0.8272\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.3777 - r1_loss: 0.1948 - r2_loss: 0.1017 - r3_loss: 0.3354 - r1_accuracy: 0.9148 - r2_accuracy: 0.9570 - r3_accuracy: 0.8456 - val_loss: 0.4068 - val_r1_loss: 0.2063 - val_r2_loss: 0.1116 - val_r3_loss: 0.3618 - val_r1_accuracy: 0.9091 - val_r2_accuracy: 0.9531 - val_r3_accuracy: 0.8295\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.3766 - r1_loss: 0.1932 - r2_loss: 0.1006 - r3_loss: 0.3346 - r1_accuracy: 0.9163 - r2_accuracy: 0.9577 - r3_accuracy: 0.8465 - val_loss: 0.4033 - val_r1_loss: 0.2072 - val_r2_loss: 0.1089 - val_r3_loss: 0.3583 - val_r1_accuracy: 0.9083 - val_r2_accuracy: 0.9528 - val_r3_accuracy: 0.8292\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.3730 - r1_loss: 0.1945 - r2_loss: 0.1017 - r3_loss: 0.3312 - r1_accuracy: 0.9147 - r2_accuracy: 0.9571 - r3_accuracy: 0.8483 - val_loss: 0.3993 - val_r1_loss: 0.2037 - val_r2_loss: 0.1080 - val_r3_loss: 0.3554 - val_r1_accuracy: 0.9105 - val_r2_accuracy: 0.9535 - val_r3_accuracy: 0.8336\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3685 - r1_loss: 0.1916 - r2_loss: 0.1003 - r3_loss: 0.3274 - r1_accuracy: 0.9166 - r2_accuracy: 0.9575 - r3_accuracy: 0.8507 - val_loss: 0.3969 - val_r1_loss: 0.2046 - val_r2_loss: 0.1054 - val_r3_loss: 0.3530 - val_r1_accuracy: 0.9098 - val_r2_accuracy: 0.9549 - val_r3_accuracy: 0.8325\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.3641 - r1_loss: 0.1920 - r2_loss: 0.0990 - r3_loss: 0.3235 - r1_accuracy: 0.9171 - r2_accuracy: 0.9577 - r3_accuracy: 0.8527 - val_loss: 0.3928 - val_r1_loss: 0.2045 - val_r2_loss: 0.1062 - val_r3_loss: 0.3495 - val_r1_accuracy: 0.9099 - val_r2_accuracy: 0.9551 - val_r3_accuracy: 0.8372\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 0.3592 - r1_loss: 0.1906 - r2_loss: 0.0981 - r3_loss: 0.3191 - r1_accuracy: 0.9173 - r2_accuracy: 0.9584 - r3_accuracy: 0.8561 - val_loss: 0.3909 - val_r1_loss: 0.2032 - val_r2_loss: 0.1074 - val_r3_loss: 0.3479 - val_r1_accuracy: 0.9104 - val_r2_accuracy: 0.9535 - val_r3_accuracy: 0.8370\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3569 - r1_loss: 0.1903 - r2_loss: 0.0982 - r3_loss: 0.3168 - r1_accuracy: 0.9169 - r2_accuracy: 0.9582 - r3_accuracy: 0.8557 - val_loss: 0.3867 - val_r1_loss: 0.2013 - val_r2_loss: 0.1065 - val_r3_loss: 0.3441 - val_r1_accuracy: 0.9115 - val_r2_accuracy: 0.9537 - val_r3_accuracy: 0.8385\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.3537 - r1_loss: 0.1894 - r2_loss: 0.0978 - r3_loss: 0.3140 - r1_accuracy: 0.9177 - r2_accuracy: 0.9589 - r3_accuracy: 0.8577 - val_loss: 0.3820 - val_r1_loss: 0.2019 - val_r2_loss: 0.1026 - val_r3_loss: 0.3397 - val_r1_accuracy: 0.9100 - val_r2_accuracy: 0.9567 - val_r3_accuracy: 0.8433\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.3482 - r1_loss: 0.1905 - r2_loss: 0.0950 - r3_loss: 0.3087 - r1_accuracy: 0.9177 - r2_accuracy: 0.9595 - r3_accuracy: 0.8605 - val_loss: 0.3803 - val_r1_loss: 0.1993 - val_r2_loss: 0.1038 - val_r3_loss: 0.3385 - val_r1_accuracy: 0.9119 - val_r2_accuracy: 0.9556 - val_r3_accuracy: 0.8432\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 0.3472 - r1_loss: 0.1885 - r2_loss: 0.0945 - r3_loss: 0.3085 - r1_accuracy: 0.9183 - r2_accuracy: 0.9602 - r3_accuracy: 0.8609 - val_loss: 0.3807 - val_r1_loss: 0.1991 - val_r2_loss: 0.1025 - val_r3_loss: 0.3397 - val_r1_accuracy: 0.9123 - val_r2_accuracy: 0.9567 - val_r3_accuracy: 0.8417\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.3428 - r1_loss: 0.1867 - r2_loss: 0.0957 - r3_loss: 0.3043 - r1_accuracy: 0.9186 - r2_accuracy: 0.9592 - r3_accuracy: 0.8614 - val_loss: 0.3743 - val_r1_loss: 0.2023 - val_r2_loss: 0.1015 - val_r3_loss: 0.3328 - val_r1_accuracy: 0.9114 - val_r2_accuracy: 0.9570 - val_r3_accuracy: 0.8452\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 0.3390 - r1_loss: 0.1876 - r2_loss: 0.0941 - r3_loss: 0.3009 - r1_accuracy: 0.9188 - r2_accuracy: 0.9603 - r3_accuracy: 0.8644 - val_loss: 0.3720 - val_r1_loss: 0.1971 - val_r2_loss: 0.0998 - val_r3_loss: 0.3320 - val_r1_accuracy: 0.9143 - val_r2_accuracy: 0.9579 - val_r3_accuracy: 0.8460\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 0.3363 - r1_loss: 0.1866 - r2_loss: 0.0923 - r3_loss: 0.2986 - r1_accuracy: 0.9200 - r2_accuracy: 0.9611 - r3_accuracy: 0.8654 - val_loss: 0.3674 - val_r1_loss: 0.1958 - val_r2_loss: 0.0987 - val_r3_loss: 0.3277 - val_r1_accuracy: 0.9145 - val_r2_accuracy: 0.9585 - val_r3_accuracy: 0.8486\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.3332 - r1_loss: 0.1858 - r2_loss: 0.0928 - r3_loss: 0.2959 - r1_accuracy: 0.9195 - r2_accuracy: 0.9610 - r3_accuracy: 0.8663 - val_loss: 0.3660 - val_r1_loss: 0.1979 - val_r2_loss: 0.0996 - val_r3_loss: 0.3262 - val_r1_accuracy: 0.9135 - val_r2_accuracy: 0.9578 - val_r3_accuracy: 0.8507\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 0.3284 - r1_loss: 0.1856 - r2_loss: 0.0926 - r3_loss: 0.2910 - r1_accuracy: 0.9195 - r2_accuracy: 0.9609 - r3_accuracy: 0.8697 - val_loss: 0.3596 - val_r1_loss: 0.1959 - val_r2_loss: 0.0979 - val_r3_loss: 0.3201 - val_r1_accuracy: 0.9149 - val_r2_accuracy: 0.9588 - val_r3_accuracy: 0.8529\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3244 - r1_loss: 0.1835 - r2_loss: 0.0915 - r3_loss: 0.2880 - r1_accuracy: 0.9211 - r2_accuracy: 0.9616 - r3_accuracy: 0.8700 - val_loss: 0.3563 - val_r1_loss: 0.1965 - val_r2_loss: 0.0979 - val_r3_loss: 0.3173 - val_r1_accuracy: 0.9147 - val_r2_accuracy: 0.9584 - val_r3_accuracy: 0.8550\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.3208 - r1_loss: 0.1818 - r2_loss: 0.0905 - r3_loss: 0.2848 - r1_accuracy: 0.9219 - r2_accuracy: 0.9619 - r3_accuracy: 0.8723 - val_loss: 0.3531 - val_r1_loss: 0.1976 - val_r2_loss: 0.0961 - val_r3_loss: 0.3141 - val_r1_accuracy: 0.9129 - val_r2_accuracy: 0.9591 - val_r3_accuracy: 0.8539\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 0.3197 - r1_loss: 0.1856 - r2_loss: 0.0884 - r3_loss: 0.2835 - r1_accuracy: 0.9196 - r2_accuracy: 0.9629 - r3_accuracy: 0.8734 - val_loss: 0.3532 - val_r1_loss: 0.1929 - val_r2_loss: 0.0976 - val_r3_loss: 0.3152 - val_r1_accuracy: 0.9151 - val_r2_accuracy: 0.9592 - val_r3_accuracy: 0.8551\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 0.3171 - r1_loss: 0.1835 - r2_loss: 0.0894 - r3_loss: 0.2808 - r1_accuracy: 0.9207 - r2_accuracy: 0.9616 - r3_accuracy: 0.8752 - val_loss: 0.3503 - val_r1_loss: 0.1937 - val_r2_loss: 0.0962 - val_r3_loss: 0.3118 - val_r1_accuracy: 0.9158 - val_r2_accuracy: 0.9583 - val_r3_accuracy: 0.8576\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.3118 - r1_loss: 0.1847 - r2_loss: 0.0888 - r3_loss: 0.2754 - r1_accuracy: 0.9206 - r2_accuracy: 0.9623 - r3_accuracy: 0.8768 - val_loss: 0.3469 - val_r1_loss: 0.1934 - val_r2_loss: 0.0967 - val_r3_loss: 0.3085 - val_r1_accuracy: 0.9148 - val_r2_accuracy: 0.9592 - val_r3_accuracy: 0.8586\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.3110 - r1_loss: 0.1809 - r2_loss: 0.0880 - r3_loss: 0.2756 - r1_accuracy: 0.9220 - r2_accuracy: 0.9629 - r3_accuracy: 0.8781 - val_loss: 0.3439 - val_r1_loss: 0.1938 - val_r2_loss: 0.0937 - val_r3_loss: 0.3061 - val_r1_accuracy: 0.9146 - val_r2_accuracy: 0.9604 - val_r3_accuracy: 0.8590\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.3085 - r1_loss: 0.1803 - r2_loss: 0.0871 - r3_loss: 0.2736 - r1_accuracy: 0.9225 - r2_accuracy: 0.9635 - r3_accuracy: 0.8787 - val_loss: 0.3383 - val_r1_loss: 0.1932 - val_r2_loss: 0.0928 - val_r3_loss: 0.3010 - val_r1_accuracy: 0.9159 - val_r2_accuracy: 0.9603 - val_r3_accuracy: 0.8619\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.3041 - r1_loss: 0.1817 - r2_loss: 0.0855 - r3_loss: 0.2693 - r1_accuracy: 0.9216 - r2_accuracy: 0.9645 - r3_accuracy: 0.8804 - val_loss: 0.3389 - val_r1_loss: 0.1932 - val_r2_loss: 0.0934 - val_r3_loss: 0.3016 - val_r1_accuracy: 0.9153 - val_r2_accuracy: 0.9604 - val_r3_accuracy: 0.8621\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.3005 - r1_loss: 0.1815 - r2_loss: 0.0847 - r3_loss: 0.2658 - r1_accuracy: 0.9222 - r2_accuracy: 0.9645 - r3_accuracy: 0.8827 - val_loss: 0.3353 - val_r1_loss: 0.1929 - val_r2_loss: 0.0905 - val_r3_loss: 0.2984 - val_r1_accuracy: 0.9152 - val_r2_accuracy: 0.9622 - val_r3_accuracy: 0.8642\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2979 - r1_loss: 0.1797 - r2_loss: 0.0850 - r3_loss: 0.2639 - r1_accuracy: 0.9229 - r2_accuracy: 0.9646 - r3_accuracy: 0.8833 - val_loss: 0.3308 - val_r1_loss: 0.1905 - val_r2_loss: 0.0919 - val_r3_loss: 0.2946 - val_r1_accuracy: 0.9167 - val_r2_accuracy: 0.9612 - val_r3_accuracy: 0.8656\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2952 - r1_loss: 0.1780 - r2_loss: 0.0843 - r3_loss: 0.2617 - r1_accuracy: 0.9239 - r2_accuracy: 0.9652 - r3_accuracy: 0.8854 - val_loss: 0.3293 - val_r1_loss: 0.1883 - val_r2_loss: 0.0919 - val_r3_loss: 0.2936 - val_r1_accuracy: 0.9178 - val_r2_accuracy: 0.9619 - val_r3_accuracy: 0.8658\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2935 - r1_loss: 0.1775 - r2_loss: 0.0835 - r3_loss: 0.2604 - r1_accuracy: 0.9245 - r2_accuracy: 0.9649 - r3_accuracy: 0.8847 - val_loss: 0.3314 - val_r1_loss: 0.1883 - val_r2_loss: 0.0903 - val_r3_loss: 0.2961 - val_r1_accuracy: 0.9170 - val_r2_accuracy: 0.9623 - val_r3_accuracy: 0.8651\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2905 - r1_loss: 0.1778 - r2_loss: 0.0835 - r3_loss: 0.2575 - r1_accuracy: 0.9238 - r2_accuracy: 0.9653 - r3_accuracy: 0.8873 - val_loss: 0.3236 - val_r1_loss: 0.1875 - val_r2_loss: 0.0910 - val_r3_loss: 0.2886 - val_r1_accuracy: 0.9181 - val_r2_accuracy: 0.9613 - val_r3_accuracy: 0.8694\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2871 - r1_loss: 0.1767 - r2_loss: 0.0811 - r3_loss: 0.2544 - r1_accuracy: 0.9243 - r2_accuracy: 0.9668 - r3_accuracy: 0.8876 - val_loss: 0.3242 - val_r1_loss: 0.1912 - val_r2_loss: 0.0884 - val_r3_loss: 0.2888 - val_r1_accuracy: 0.9169 - val_r2_accuracy: 0.9618 - val_r3_accuracy: 0.8696\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2849 - r1_loss: 0.1771 - r2_loss: 0.0818 - r3_loss: 0.2524 - r1_accuracy: 0.9235 - r2_accuracy: 0.9656 - r3_accuracy: 0.8898 - val_loss: 0.3233 - val_r1_loss: 0.1865 - val_r2_loss: 0.0879 - val_r3_loss: 0.2890 - val_r1_accuracy: 0.9191 - val_r2_accuracy: 0.9631 - val_r3_accuracy: 0.8697\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2824 - r1_loss: 0.1760 - r2_loss: 0.0802 - r3_loss: 0.2501 - r1_accuracy: 0.9244 - r2_accuracy: 0.9666 - r3_accuracy: 0.8905 - val_loss: 0.3168 - val_r1_loss: 0.1879 - val_r2_loss: 0.0880 - val_r3_loss: 0.2820 - val_r1_accuracy: 0.9185 - val_r2_accuracy: 0.9635 - val_r3_accuracy: 0.8723\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2792 - r1_loss: 0.1758 - r2_loss: 0.0791 - r3_loss: 0.2471 - r1_accuracy: 0.9239 - r2_accuracy: 0.9676 - r3_accuracy: 0.8926 - val_loss: 0.3184 - val_r1_loss: 0.1868 - val_r2_loss: 0.0876 - val_r3_loss: 0.2841 - val_r1_accuracy: 0.9183 - val_r2_accuracy: 0.9631 - val_r3_accuracy: 0.8733\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2760 - r1_loss: 0.1768 - r2_loss: 0.0792 - r3_loss: 0.2439 - r1_accuracy: 0.9246 - r2_accuracy: 0.9676 - r3_accuracy: 0.8941 - val_loss: 0.3142 - val_r1_loss: 0.1859 - val_r2_loss: 0.0857 - val_r3_loss: 0.2803 - val_r1_accuracy: 0.9192 - val_r2_accuracy: 0.9646 - val_r3_accuracy: 0.8745\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2739 - r1_loss: 0.1777 - r2_loss: 0.0794 - r3_loss: 0.2418 - r1_accuracy: 0.9231 - r2_accuracy: 0.9672 - r3_accuracy: 0.8947 - val_loss: 0.3098 - val_r1_loss: 0.1835 - val_r2_loss: 0.0845 - val_r3_loss: 0.2765 - val_r1_accuracy: 0.9202 - val_r2_accuracy: 0.9649 - val_r3_accuracy: 0.8759\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2726 - r1_loss: 0.1736 - r2_loss: 0.0794 - r3_loss: 0.2408 - r1_accuracy: 0.9263 - r2_accuracy: 0.9672 - r3_accuracy: 0.8946 - val_loss: 0.3099 - val_r1_loss: 0.1843 - val_r2_loss: 0.0856 - val_r3_loss: 0.2760 - val_r1_accuracy: 0.9211 - val_r2_accuracy: 0.9638 - val_r3_accuracy: 0.8765\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2700 - r1_loss: 0.1737 - r2_loss: 0.0791 - r3_loss: 0.2391 - r1_accuracy: 0.9254 - r2_accuracy: 0.9669 - r3_accuracy: 0.8960 - val_loss: 0.3070 - val_r1_loss: 0.1848 - val_r2_loss: 0.0854 - val_r3_loss: 0.2740 - val_r1_accuracy: 0.9213 - val_r2_accuracy: 0.9648 - val_r3_accuracy: 0.8772\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2673 - r1_loss: 0.1728 - r2_loss: 0.0769 - r3_loss: 0.2364 - r1_accuracy: 0.9268 - r2_accuracy: 0.9688 - r3_accuracy: 0.8973 - val_loss: 0.3073 - val_r1_loss: 0.1823 - val_r2_loss: 0.0857 - val_r3_loss: 0.2744 - val_r1_accuracy: 0.9204 - val_r2_accuracy: 0.9642 - val_r3_accuracy: 0.8767\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2642 - r1_loss: 0.1727 - r2_loss: 0.0776 - r3_loss: 0.2338 - r1_accuracy: 0.9267 - r2_accuracy: 0.9679 - r3_accuracy: 0.8994 - val_loss: 0.3020 - val_r1_loss: 0.1811 - val_r2_loss: 0.0869 - val_r3_loss: 0.2698 - val_r1_accuracy: 0.9210 - val_r2_accuracy: 0.9630 - val_r3_accuracy: 0.8792\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2615 - r1_loss: 0.1716 - r2_loss: 0.0768 - r3_loss: 0.2313 - r1_accuracy: 0.9265 - r2_accuracy: 0.9684 - r3_accuracy: 0.8999 - val_loss: 0.3005 - val_r1_loss: 0.1817 - val_r2_loss: 0.0840 - val_r3_loss: 0.2684 - val_r1_accuracy: 0.9217 - val_r2_accuracy: 0.9652 - val_r3_accuracy: 0.8784\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2597 - r1_loss: 0.1709 - r2_loss: 0.0772 - r3_loss: 0.2297 - r1_accuracy: 0.9273 - r2_accuracy: 0.9681 - r3_accuracy: 0.9015 - val_loss: 0.2987 - val_r1_loss: 0.1815 - val_r2_loss: 0.0821 - val_r3_loss: 0.2668 - val_r1_accuracy: 0.9217 - val_r2_accuracy: 0.9658 - val_r3_accuracy: 0.8809\n",
      "Early Stop!\n",
      "Memory cost: 3.16 GiB\n"
     ]
    }
   ],
   "source": [
    "units_mmoe = 32\n",
    "model = None\n",
    "import pandas as pd\n",
    "######################################################################\n",
    "# gate_activation = [CustomSoftmaxThre(threshold=1) for _ in range(PUF_list.n_pufs)]\n",
    "## The change the total number of experts\n",
    "num_experts = 20\n",
    "gate_activation = [CustomSoftmaxExperts(experts_needed=5,threshold=0.00001) for _ in range(PUF_list.n_pufs)]\n",
    "# output_info = ['r'+str(i) for i in range(1,PUF_list.n_pufs+1)]\n",
    "\n",
    "# gate_activation = CustomSoftmaxExperts(experts_needed=5)\n",
    "# gate_activation = [activations.get('softmax')]\n",
    "\n",
    "\n",
    "model,history, output_info, train_losses, train_accuracies, val_losses, val_accuracies = Model_Multiple_PUFs(\n",
    "    units_mmoe=units_mmoe,\n",
    "    gate_activation=gate_activation,\n",
    "    N_train=N_train,\n",
    "    train_c=train_c,\n",
    "    test_c=test_c,\n",
    "    train_r_groups=train_r_groups,\n",
    "    test_r_groups=test_r_groups,\n",
    "    PUF_list=PUF_list,\n",
    "    num_expert=num_experts\n",
    ")\n",
    "\n",
    "memory_info_end = process.memory_info() \n",
    "\n",
    "# Memory cost\n",
    "print(f\"Memory cost: {(memory_info_end.rss- memory_info_start.rss) / (1024 ** 3):.2f} GiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide the demo with \"early stop at 90\\%\", to get the results from the paper, please set the stop accuracy to 95\\%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
